{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhtrung102/CSUET-AI/blob/main/search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup search"
      ],
      "metadata": {
        "id": "MrfJBGZFCKOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aimacode/aima-python.git\n",
        "%cd /content/aima-python\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "%pwd\n",
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm-rUmVsCJGi",
        "outputId": "43fec749-f088-4458-8f14-7c95b41bb81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'aima-python' already exists and is not an empty directory.\n",
            "/content/aima-python\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.33)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (7.34.0)\n",
            "Requirement already satisfied: ipythonblocks in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.9.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (7.7.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.1.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (10.4.0)\n",
            "Requirement already satisfied: pytest-cov in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (5.0.0)\n",
            "Requirement already satisfied: qpsolvers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (4.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.17.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (from image->-r requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from image->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.0 in /usr/local/lib/python3.10/dist-packages (from ipythonblocks->-r requirements.txt (line 4)) (6.5.5)\n",
            "Requirement already satisfied: requests>=1.0 in /usr/local/lib/python3.10/dist-packages (from ipythonblocks->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->-r requirements.txt (line 5)) (6.29.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->-r requirements.txt (line 5)) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->-r requirements.txt (line 5)) (3.0.13)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 6)) (6.5.4)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 6)) (4.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras->-r requirements.txt (line 7)) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2024.1)\n",
            "Requirement already satisfied: pytest>=4.6 in /usr/local/lib/python3.10/dist-packages (from pytest-cov->-r requirements.txt (line 14)) (7.4.4)\n",
            "Requirement already satisfied: coverage>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from coverage[toml]>=5.2.1->pytest-cov->-r requirements.txt (line 14)) (7.6.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (3.20.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 18)) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 18)) (0.44.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from coverage[toml]>=5.2.1->pytest-cov->-r requirements.txt (line 14)) (2.0.1)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (1.6.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (7.4.9)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (5.7.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.0->ipythonblocks->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->pytest-cov->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->pytest-cov->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->pytest-cov->-r requirements.txt (line 14)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=1.0->ipythonblocks->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=1.0->ipythonblocks->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=1.0->ipythonblocks->-r requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=1.0->ipythonblocks->-r requirements.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 18)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 18)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 18)) (3.0.4)\n",
            "Requirement already satisfied: asgiref<4,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from django->image->-r requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django->image->-r requirements.txt (line 2)) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rUmmCqPQCBYB"
      },
      "source": [
        "# Solving problems by Searching\n",
        "\n",
        "This notebook serves as supporting material for topics covered in **Chapter 3 - Solving Problems by Searching** and **Chapter 4 - Beyond Classical Search** from the book *Artificial Intelligence: A Modern Approach.* This notebook uses implementations from [search.py](https://github.com/aimacode/aima-python/blob/master/search.py) module. Let's start by importing everything from search module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PBDFR7NdCBYD"
      },
      "outputs": [],
      "source": [
        "from search import *\n",
        "from notebook import psource, heatmap, gaussian_kernel, show_map, final_path_colors, display_visual, plot_NQueens\n",
        "\n",
        "# Needed to hide warnings in the matplotlib sections\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKYpp9XwCBYE"
      },
      "source": [
        "## CONTENTS\n",
        "\n",
        "* Overview\n",
        "* Problem\n",
        "* Node\n",
        "* Simple Problem Solving Agent\n",
        "* Search Algorithms Visualization\n",
        "* Breadth-First Tree Search\n",
        "* Breadth-First Search\n",
        "* Best First Search\n",
        "* Uniform Cost Search\n",
        "* Greedy Best First Search\n",
        "* A\\* Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdcwqCdhCBYE"
      },
      "source": [
        "## OVERVIEW\n",
        "\n",
        "Here, we learn about a specific kind of problem solving - building goal-based agents that can plan ahead to solve problems. In particular, we examine navigation problem/route finding problem. We must begin by precisely defining **problems** and their **solutions**. We will look at several general-purpose search algorithms.\n",
        "\n",
        "Search algorithms can be classified into two types:\n",
        "\n",
        "* **Uninformed search algorithms**: Search algorithms which explore the search space without having any information about the problem other than its definition.\n",
        "    * Examples:\n",
        "        1. Breadth First Search\n",
        "        2. Depth First Search\n",
        "        3. Depth Limited Search\n",
        "        4. Iterative Deepening Search\n",
        "\n",
        "\n",
        "* **Informed search algorithms**: These type of algorithms leverage any information (heuristics, path cost) on the problem to search through the search space to find the solution efficiently.\n",
        "    * Examples:\n",
        "        1. Best First Search\n",
        "        2. Uniform Cost Search\n",
        "        3. A\\* Search\n",
        "        4. Recursive Best First Search\n",
        "\n",
        "*Don't miss the visualisations of these algorithms solving the route-finding problem defined on Romania map at the end of this notebook.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzdeT8E8CBYE"
      },
      "source": [
        "For visualisations, we use networkx and matplotlib to show the map in the notebook and we use ipywidgets to interact with the map to see how the searching algorithm works. These are imported as required in `notebook.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uOEfKxdCBYF"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import lines\n",
        "\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "infinity = float(\"inf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVdPMHCmCBYF"
      },
      "source": [
        "## PROBLEM\n",
        "\n",
        "Let's see how we define a Problem. Run the next cell to see how abstract class `Problem` is defined in the search module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Nh_JVnCBYF"
      },
      "outputs": [],
      "source": [
        "psource(Problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKJvXAYkCBYG"
      },
      "source": [
        "The `Problem` class has six methods.\n",
        "\n",
        "* `__init__(self, initial, goal)` : This is what is called a `constructor`. It is the first method called when you create an instance of the class as `Problem(initial, goal)`. The variable `initial` specifies the initial state $s_0$ of the search problem. It represents the beginning state. From here, our agent begins its task of exploration to find the goal state(s) which is given in the `goal` parameter.\n",
        "\n",
        "\n",
        "* `actions(self, state)` : This method returns all the possible actions agent can execute in the given state `state`.\n",
        "\n",
        "\n",
        "* `result(self, state, action)` : This returns the resulting state if action `action` is taken in the state `state`. This `Problem` class only deals with deterministic outcomes. So we know for sure what every action in a state would result to.\n",
        "\n",
        "\n",
        "* `goal_test(self, state)` : Return a boolean for a given state - `True` if it is a goal state, else `False`.\n",
        "\n",
        "\n",
        "* `path_cost(self, c, state1, action, state2)` : Return the cost of the path that arrives at `state2` as a result of taking `action` from `state1`, assuming total cost of `c` to get up to `state1`.\n",
        "\n",
        "\n",
        "* `value(self, state)` : This acts as a bit of extra information in problems where we try to optimise a value when we cannot do a goal test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfbe_gNaCBYG"
      },
      "source": [
        "## NODE\n",
        "\n",
        "Let's see how we define a Node. Run the next cell to see how abstract class `Node` is defined in the search module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HKQhqkTCBYG"
      },
      "outputs": [],
      "source": [
        "psource(Node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvL2GkxHCBYH"
      },
      "source": [
        "The `Node` class has nine methods. The first is the `__init__` method.\n",
        "\n",
        "* `__init__(self, state, parent, action, path_cost)` : This method creates a node. `parent` represents the node that this is a successor of and `action` is the action required to get from the parent node to this node. `path_cost` is the cost to reach current node from parent node.\n",
        "\n",
        "The next 4 methods are specific `Node`-related functions.\n",
        "\n",
        "* `expand(self, problem)` : This method lists all the neighbouring(reachable in one step) nodes of current node.\n",
        "\n",
        "* `child_node(self, problem, action)` : Given an `action`, this method returns the immediate neighbour that can be reached with that `action`.\n",
        "\n",
        "* `solution(self)` : This returns the sequence of actions required to reach this node from the root node.\n",
        "\n",
        "* `path(self)` : This returns a list of all the nodes that lies in the path from the root to this node.\n",
        "\n",
        "The remaining 4 methods override standards Python functionality for representing an object as a string, the less-than ($<$) operator, the equal-to ($=$) operator, and the `hash` function.\n",
        "\n",
        "* `__repr__(self)` : This returns the state of this node.\n",
        "\n",
        "* `__lt__(self, node)` : Given a `node`, this method returns `True` if the state of current node is less than the state of the `node`. Otherwise it returns `False`.\n",
        "\n",
        "* `__eq__(self, other)` : This method returns `True` if the state of current node is equal to the other node. Else it returns `False`.\n",
        "\n",
        "* `__hash__(self)` : This returns the hash of the state of current node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1L4Uq7YCBYH"
      },
      "source": [
        "We will use the abstract class `Problem` to define our real **problem** named `GraphProblem`. You can see how we define `GraphProblem` by running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_tnzVgUCBYH"
      },
      "outputs": [],
      "source": [
        "psource(GraphProblem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0QFePYCBYH"
      },
      "source": [
        "Have a look at our romania_map, which is an Undirected Graph containing a dict of nodes as keys and neighbours as values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NopvaEXGCBYH"
      },
      "outputs": [],
      "source": [
        "romania_map = UndirectedGraph(dict(\n",
        "    Arad=dict(Zerind=75, Sibiu=140, Timisoara=118),\n",
        "    Bucharest=dict(Urziceni=85, Pitesti=101, Giurgiu=90, Fagaras=211),\n",
        "    Craiova=dict(Drobeta=120, Rimnicu=146, Pitesti=138),\n",
        "    Drobeta=dict(Mehadia=75),\n",
        "    Eforie=dict(Hirsova=86),\n",
        "    Fagaras=dict(Sibiu=99),\n",
        "    Hirsova=dict(Urziceni=98),\n",
        "    Iasi=dict(Vaslui=92, Neamt=87),\n",
        "    Lugoj=dict(Timisoara=111, Mehadia=70),\n",
        "    Oradea=dict(Zerind=71, Sibiu=151),\n",
        "    Pitesti=dict(Rimnicu=97),\n",
        "    Rimnicu=dict(Sibiu=80),\n",
        "    Urziceni=dict(Vaslui=142)))\n",
        "\n",
        "romania_map.locations = dict(\n",
        "    Arad=(91, 492), Bucharest=(400, 327), Craiova=(253, 288),\n",
        "    Drobeta=(165, 299), Eforie=(562, 293), Fagaras=(305, 449),\n",
        "    Giurgiu=(375, 270), Hirsova=(534, 350), Iasi=(473, 506),\n",
        "    Lugoj=(165, 379), Mehadia=(168, 339), Neamt=(406, 537),\n",
        "    Oradea=(131, 571), Pitesti=(320, 368), Rimnicu=(233, 410),\n",
        "    Sibiu=(207, 457), Timisoara=(94, 410), Urziceni=(456, 350),\n",
        "    Vaslui=(509, 444), Zerind=(108, 531))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "5f8n0fqECBYH"
      },
      "source": [
        "It is pretty straightforward to understand this `romania_map`. The first node **Arad** has three neighbours named **Zerind**, **Sibiu**, **Timisoara**. Each of these nodes are 75, 140, 118 units apart from **Arad** respectively. And the same goes with other nodes.\n",
        "\n",
        "And `romania_map.locations` contains the positions of each of the nodes. We will use the straight line distance (which is different from the one provided in `romania_map`) between two cities in algorithms like A\\*-search and Recursive Best First Search.\n",
        "\n",
        "**Define a problem:**\n",
        "Now it's time to define our problem. We will define it by passing `initial`, `goal`, `graph` to `GraphProblem`. So, our problem is to find the goal state starting from the given initial state on the provided graph.\n",
        "\n",
        "Say we want to start exploring from **Arad** and try to find **Bucharest** in our romania_map. So, this is how we do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7kyIfioCBYI"
      },
      "outputs": [],
      "source": [
        "romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwvzbiKCBYI"
      },
      "source": [
        "### Romania Map Visualisation\n",
        "\n",
        "Let's have a visualisation of Romania map [Figure 3.2] from the book and see how different searching algorithms perform / how frontier expands in each search algorithm for a simple problem named `romania_problem`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9yD2KuHCBYI"
      },
      "source": [
        "Have a look at `romania_locations`. It is a dictionary defined in search module. We will use these location values to draw the romania graph using **networkx**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CTJmtQkCBYI"
      },
      "outputs": [],
      "source": [
        "romania_locations = romania_map.locations\n",
        "print(romania_locations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2RKejIxCBYI"
      },
      "source": [
        "Let's get started by initializing an empty graph. We will add nodes, place the nodes in their location as shown in the book, add edges to the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE1h_rcHCBYI"
      },
      "outputs": [],
      "source": [
        "# node colors, node positions and node label positions\n",
        "node_colors = {node: 'white' for node in romania_map.locations.keys()}\n",
        "node_positions = romania_map.locations\n",
        "node_label_pos = { k:[v[0],v[1]-10]  for k,v in romania_map.locations.items() }\n",
        "edge_weights = {(k, k2) : v2 for k, v in romania_map.graph_dict.items() for k2, v2 in v.items()}\n",
        "\n",
        "romania_graph_data = {  'graph_dict' : romania_map.graph_dict,\n",
        "                        'node_colors': node_colors,\n",
        "                        'node_positions': node_positions,\n",
        "                        'node_label_positions': node_label_pos,\n",
        "                         'edge_weights': edge_weights\n",
        "                     }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIDklN8kCBYI"
      },
      "source": [
        "We have completed building our graph based on romania_map and its locations. It's time to display it here in the notebook. This function `show_map(node_colors)` helps us do that. We will be calling this function later on to display the map at each and every interval step while searching, using variety of algorithms from the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDxZz3myCBYI"
      },
      "source": [
        "We can simply call the function with node_colors dictionary object to display it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "7PEY2j70CBYJ"
      },
      "outputs": [],
      "source": [
        "show_map(romania_graph_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5awLLKKRCBYJ"
      },
      "source": [
        "Voila! You see, the romania map as shown in the Figure[3.2] in the book. Now, see how different searching algorithms perform with our problem statements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LklDuVMXCBYJ"
      },
      "source": [
        "## SIMPLE PROBLEM SOLVING AGENT PROGRAM\n",
        "\n",
        "Let us now define a Simple Problem Solving Agent Program. Run the next cell to see how the abstract class `SimpleProblemSolvingAgentProgram` is defined in the search module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwResjJcCBYJ"
      },
      "outputs": [],
      "source": [
        "psource(SimpleProblemSolvingAgentProgram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6NBdtYCBYJ"
      },
      "source": [
        "The SimpleProblemSolvingAgentProgram class has six methods:  \n",
        "\n",
        "* `__init__(self, intial_state=None)`: This is the `contructor` of the class and is the first method to be called when the class is instantiated. It takes in a keyword argument, `initial_state` which is initially `None`. The argument `initial_state` represents the state from which the agent starts.\n",
        "\n",
        "* `__call__(self, percept)`: This method updates the `state` of the agent based on its `percept` using the `update_state` method. It then formulates a `goal` with the help of `formulate_goal` method and a `problem` using the `formulate_problem` method and returns a sequence of actions to solve it (using the `search` method).\n",
        "\n",
        "* `update_state(self, percept)`: This method updates the `state` of the agent based on its `percept`.\n",
        "\n",
        "* `formulate_goal(self, state)`: Given a `state` of the agent, this method formulates the `goal` for it.\n",
        "\n",
        "* `formulate_problem(self, state, goal)`: It is used in problem formulation given a `state` and a `goal` for the `agent`.\n",
        "\n",
        "* `search(self, problem)`: This method is used to search a sequence of `actions` to solve a `problem`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlg5CB9kCBYJ"
      },
      "source": [
        "Let us now define a Simple Problem Solving Agent Program. We will create a simple `vacuumAgent` class which will inherit from the abstract class `SimpleProblemSolvingAgentProgram` and overrides its methods. We will create a simple intelligent vacuum agent which can be in any one of the following states. It will move to any other state depending upon the current state as shown in the picture by arrows:\n",
        "\n",
        "![simple problem solving agent](images/simple_problem_solving_agent.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSwYAKH_CBYK"
      },
      "outputs": [],
      "source": [
        "class vacuumAgent(SimpleProblemSolvingAgentProgram):\n",
        "        def update_state(self, state, percept):\n",
        "            return percept\n",
        "\n",
        "        def formulate_goal(self, state):\n",
        "            goal = [state7, state8]\n",
        "            return goal\n",
        "\n",
        "        def formulate_problem(self, state, goal):\n",
        "            problem = state\n",
        "            return problem\n",
        "\n",
        "        def search(self, problem):\n",
        "            if problem == state1:\n",
        "                seq = [\"Suck\", \"Right\", \"Suck\"]\n",
        "            elif problem == state2:\n",
        "                seq = [\"Suck\", \"Left\", \"Suck\"]\n",
        "            elif problem == state3:\n",
        "                seq = [\"Right\", \"Suck\"]\n",
        "            elif problem == state4:\n",
        "                seq = [\"Suck\"]\n",
        "            elif problem == state5:\n",
        "                seq = [\"Suck\"]\n",
        "            elif problem == state6:\n",
        "                seq = [\"Left\", \"Suck\"]\n",
        "            return seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7xADCAvCBYK"
      },
      "source": [
        "Now, we will define all the 8 states and create an object of the above class. Then, we will pass it different states and check the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlpYbYoxCBYK"
      },
      "outputs": [],
      "source": [
        "state1 = [(0, 0), [(0, 0), \"Dirty\"], [(1, 0), [\"Dirty\"]]]\n",
        "state2 = [(1, 0), [(0, 0), \"Dirty\"], [(1, 0), [\"Dirty\"]]]\n",
        "state3 = [(0, 0), [(0, 0), \"Clean\"], [(1, 0), [\"Dirty\"]]]\n",
        "state4 = [(1, 0), [(0, 0), \"Clean\"], [(1, 0), [\"Dirty\"]]]\n",
        "state5 = [(0, 0), [(0, 0), \"Dirty\"], [(1, 0), [\"Clean\"]]]\n",
        "state6 = [(1, 0), [(0, 0), \"Dirty\"], [(1, 0), [\"Clean\"]]]\n",
        "state7 = [(0, 0), [(0, 0), \"Clean\"], [(1, 0), [\"Clean\"]]]\n",
        "state8 = [(1, 0), [(0, 0), \"Clean\"], [(1, 0), [\"Clean\"]]]\n",
        "\n",
        "a = vacuumAgent(state1)\n",
        "\n",
        "print(a(state6))\n",
        "print(a(state1))\n",
        "print(a(state3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IAe4gX4CBYK"
      },
      "source": [
        "## SEARCHING ALGORITHMS VISUALIZATION\n",
        "\n",
        "In this section, we have visualizations of the following searching algorithms:\n",
        "\n",
        "1. Breadth First Tree Search\n",
        "2. Depth First Tree Search\n",
        "3. Breadth First Search\n",
        "4. Depth First Graph Search\n",
        "5. Best First Graph Search\n",
        "6. Uniform Cost Search\n",
        "7. Depth Limited Search\n",
        "8. Iterative Deepening Search\n",
        "9. Greedy Best First Search\n",
        "9. A\\*-Search\n",
        "10. Recursive Best First Search\n",
        "\n",
        "We add the colors to the nodes to have a nice visualisation when displaying. So, these are the different colors we are using in these visuals:\n",
        "* Un-explored nodes - <font color='black'>white</font>\n",
        "* Frontier nodes - <font color='orange'>orange</font>\n",
        "* Currently exploring node - <font color='red'>red</font>\n",
        "* Already explored nodes - <font color='gray'>gray</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4kyRWgGCBYK"
      },
      "source": [
        "## 1. BREADTH-FIRST TREE SEARCH\n",
        "\n",
        "We have a working implementation in search module. But as we want to interact with the graph while it is searching, we need to modify the implementation. Here's the modified breadth first tree search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1snte3voCBYK"
      },
      "outputs": [],
      "source": [
        "def tree_breadth_search_for_vis(problem):\n",
        "    \"\"\"Search through the successors of a problem to find a goal.\n",
        "    The argument frontier should be an empty queue.\n",
        "    Don't worry about repeated paths to a state. [Figure 3.7]\"\"\"\n",
        "\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    #Adding first node to the queue\n",
        "    frontier = deque([Node(problem.initial)])\n",
        "\n",
        "    node_colors[Node(problem.initial).state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    while frontier:\n",
        "        #Popping first node of queue\n",
        "        node = frontier.popleft()\n",
        "\n",
        "        # modify the currently searching node to red\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            # modify goal node to green after reaching the goal\n",
        "            node_colors[node.state] = \"green\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            return(iterations, all_node_colors, node)\n",
        "\n",
        "        frontier.extend(node.expand(problem))\n",
        "\n",
        "        for n in node.expand(problem):\n",
        "            node_colors[n.state] = \"orange\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        # modify the color of explored nodes to gray\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    return None\n",
        "\n",
        "def breadth_first_tree_search(problem):\n",
        "    \"Search the shallowest nodes in the search tree first.\"\n",
        "    iterations, all_node_colors, node = tree_breadth_search_for_vis(problem)\n",
        "    return(iterations, all_node_colors, node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNUHASFWCBYL"
      },
      "source": [
        "Now, we use `ipywidgets` to display a slider, a button and our romania map. By sliding the slider we can have a look at all the intermediate steps of a particular search algorithm. By pressing the button **Visualize**, you can see all the steps without interacting with the slider. These two helper functions are the callback functions which are called when we interact with the slider and the button."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IwWMEIYCBYL"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# a, b, c = breadth_first_tree_search(romania_problem)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=breadth_first_tree_search,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNahc2y7CBYP"
      },
      "source": [
        "## 2. DEPTH-FIRST TREE SEARCH\n",
        "Now let's discuss another searching algorithm, Depth-First Tree Search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC6lcJBUCBYP"
      },
      "outputs": [],
      "source": [
        "def tree_depth_search_for_vis(problem):\n",
        "    \"\"\"Search through the successors of a problem to find a goal.\n",
        "    The argument frontier should be an empty queue.\n",
        "    Don't worry about repeated paths to a state. [Figure 3.7]\"\"\"\n",
        "\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    #Adding first node to the stack\n",
        "    frontier = [Node(problem.initial)]\n",
        "\n",
        "    node_colors[Node(problem.initial).state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    while frontier:\n",
        "        #Popping first node of stack\n",
        "        node = frontier.pop()\n",
        "\n",
        "        # modify the currently searching node to red\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            # modify goal node to green after reaching the goal\n",
        "            node_colors[node.state] = \"green\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            return(iterations, all_node_colors, node)\n",
        "\n",
        "        frontier.extend(node.expand(problem))\n",
        "\n",
        "        for n in node.expand(problem):\n",
        "            node_colors[n.state] = \"orange\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        # modify the color of explored nodes to gray\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    return None\n",
        "\n",
        "def depth_first_tree_search(problem):\n",
        "    \"Search the deepest nodes in the search tree first.\"\n",
        "    iterations, all_node_colors, node = tree_depth_search_for_vis(problem)\n",
        "    return(iterations, all_node_colors, node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG1BMIlECBYP"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=depth_first_tree_search,\n",
        "#                problem=romania_problem,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ms-NOmuOCBYP"
      },
      "source": [
        "## 3. BREADTH-FIRST GRAPH SEARCH\n",
        "\n",
        "Let's change all the `node_colors` to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc-t2R-fCBYP"
      },
      "outputs": [],
      "source": [
        "def breadth_first_search_graph(problem):\n",
        "    \"[Figure 3.11]\"\n",
        "\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    node = Node(problem.initial)\n",
        "\n",
        "    node_colors[node.state] = \"red\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    if problem.goal_test(node.state):\n",
        "        node_colors[node.state] = \"green\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "        return(iterations, all_node_colors, node)\n",
        "\n",
        "    frontier = deque([node])\n",
        "\n",
        "    # modify the color of frontier nodes to blue\n",
        "    node_colors[node.state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    explored = set()\n",
        "    while frontier:\n",
        "        node = frontier.popleft()\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        explored.add(node.state)\n",
        "\n",
        "        for child in node.expand(problem):\n",
        "            if child.state not in explored and child not in frontier:\n",
        "                if problem.goal_test(child.state):\n",
        "                    node_colors[child.state] = \"green\"\n",
        "                    iterations += 1\n",
        "                    all_node_colors.append(dict(node_colors))\n",
        "                    return(iterations, all_node_colors, child)\n",
        "                frontier.append(child)\n",
        "\n",
        "                node_colors[child.state] = \"orange\"\n",
        "                iterations += 1\n",
        "                all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA0_q9Q4CBYQ"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=breadth_first_search_graph,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_UWbGCyCBYQ"
      },
      "source": [
        "## 4. DEPTH-FIRST GRAPH SEARCH\n",
        "Although we have a working implementation in search module, we have to make a few changes in the algorithm to make it suitable for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JXjgV_LCBYQ"
      },
      "outputs": [],
      "source": [
        "def graph_search_for_vis(problem):\n",
        "    \"\"\"Search through the successors of a problem to find a goal.\n",
        "    The argument frontier should be an empty queue.\n",
        "    If two paths reach a state, only use the first one. [Figure 3.7]\"\"\"\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    frontier = [(Node(problem.initial))]\n",
        "    explored = set()\n",
        "\n",
        "    # modify the color of frontier nodes to orange\n",
        "    node_colors[Node(problem.initial).state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    while frontier:\n",
        "        # Popping first node of stack\n",
        "        node = frontier.pop()\n",
        "\n",
        "        # modify the currently searching node to red\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            # modify goal node to green after reaching the goal\n",
        "            node_colors[node.state] = \"green\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            return(iterations, all_node_colors, node)\n",
        "\n",
        "        explored.add(node.state)\n",
        "        frontier.extend(child for child in node.expand(problem)\n",
        "                        if child.state not in explored and\n",
        "                        child not in frontier)\n",
        "\n",
        "        for n in frontier:\n",
        "            # modify the color of frontier nodes to orange\n",
        "            node_colors[n.state] = \"orange\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        # modify the color of explored nodes to gray\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def depth_first_graph_search(problem):\n",
        "    \"\"\"Search the deepest nodes in the search tree first.\"\"\"\n",
        "    iterations, all_node_colors, node = graph_search_for_vis(problem)\n",
        "    return(iterations, all_node_colors, node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfJ_2sUJCBYQ"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=depth_first_graph_search,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-otAXRagCBYQ"
      },
      "source": [
        "## 5. BEST FIRST SEARCH\n",
        "\n",
        "Let's change all the `node_colors` to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR2NL8dfCBYR"
      },
      "outputs": [],
      "source": [
        "def best_first_graph_search_for_vis(problem, f):\n",
        "    \"\"\"Search the nodes with the lowest f scores first.\n",
        "    You specify the function f(node) that you want to minimize; for example,\n",
        "    if f is a heuristic estimate to the goal, then we have greedy best\n",
        "    first search; if f is node.depth then we have breadth-first search.\n",
        "    There is a subtlety: the line \"f = memoize(f, 'f')\" means that the f\n",
        "    values will be cached on the nodes as they are computed. So after doing\n",
        "    a best first search you can examine the f values of the path returned.\"\"\"\n",
        "\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    f = memoize(f, 'f')\n",
        "    node = Node(problem.initial)\n",
        "\n",
        "    node_colors[node.state] = \"red\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    if problem.goal_test(node.state):\n",
        "        node_colors[node.state] = \"green\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "        return(iterations, all_node_colors, node)\n",
        "\n",
        "    frontier = PriorityQueue('min', f)\n",
        "    frontier.append(node)\n",
        "\n",
        "    node_colors[node.state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    explored = set()\n",
        "    while frontier:\n",
        "        node = frontier.pop()\n",
        "\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            node_colors[node.state] = \"green\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            return(iterations, all_node_colors, node)\n",
        "\n",
        "        explored.add(node.state)\n",
        "        for child in node.expand(problem):\n",
        "            if child.state not in explored and child not in frontier:\n",
        "                frontier.append(child)\n",
        "                node_colors[child.state] = \"orange\"\n",
        "                iterations += 1\n",
        "                all_node_colors.append(dict(node_colors))\n",
        "            elif child in frontier:\n",
        "                incumbent = frontier[child]\n",
        "                if f(child) < incumbent:\n",
        "                    del frontier[child]\n",
        "                    frontier.append(child)\n",
        "                    node_colors[child.state] = \"orange\"\n",
        "                    iterations += 1\n",
        "                    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzFYNTU0CBYR"
      },
      "source": [
        "## 6. UNIFORM COST SEARCH\n",
        "\n",
        "Let's change all the `node_colors` to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSm-7ILPCBYR"
      },
      "outputs": [],
      "source": [
        "def uniform_cost_search_graph(problem):\n",
        "    \"[Figure 3.14]\"\n",
        "    #Uniform Cost Search uses Best First Search algorithm with f(n) = g(n)\n",
        "    iterations, all_node_colors, node = best_first_graph_search_for_vis(problem, lambda node: node.path_cost)\n",
        "    return(iterations, all_node_colors, node)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "lIMJmqE0CBYR"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=uniform_cost_search_graph,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLTGuPexCBYR"
      },
      "source": [
        "## 7. DEPTH LIMITED SEARCH\n",
        "\n",
        "Let's change all the 'node_colors' to starting position and define a different problem statement.  \n",
        "Although we have a working implementation, but we need to make changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ODhEFxuCBYR"
      },
      "outputs": [],
      "source": [
        "def depth_limited_search_graph(problem, limit = -1):\n",
        "    '''\n",
        "    Perform depth first search of graph g.\n",
        "    if limit >= 0, that is the maximum depth of the search.\n",
        "    '''\n",
        "    # we use these two variables at the time of visualisations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    frontier = [Node(problem.initial)]\n",
        "    explored = set()\n",
        "\n",
        "    cutoff_occurred = False\n",
        "    node_colors[Node(problem.initial).state] = \"orange\"\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    while frontier:\n",
        "        # Popping first node of queue\n",
        "        node = frontier.pop()\n",
        "\n",
        "        # modify the currently searching node to red\n",
        "        node_colors[node.state] = \"red\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            # modify goal node to green after reaching the goal\n",
        "            node_colors[node.state] = \"green\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            return(iterations, all_node_colors, node)\n",
        "\n",
        "        elif limit >= 0:\n",
        "            cutoff_occurred = True\n",
        "            limit += 1\n",
        "            all_node_colors.pop()\n",
        "            iterations -= 1\n",
        "            node_colors[node.state] = \"gray\"\n",
        "\n",
        "\n",
        "        explored.add(node.state)\n",
        "        frontier.extend(child for child in node.expand(problem)\n",
        "                        if child.state not in explored and\n",
        "                        child not in frontier)\n",
        "\n",
        "        for n in frontier:\n",
        "            limit -= 1\n",
        "            # modify the color of frontier nodes to orange\n",
        "            node_colors[n.state] = \"orange\"\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        # modify the color of explored nodes to gray\n",
        "        node_colors[node.state] = \"gray\"\n",
        "        iterations += 1\n",
        "        all_node_colors.append(dict(node_colors))\n",
        "\n",
        "    return 'cutoff' if cutoff_occurred else None\n",
        "\n",
        "\n",
        "def depth_limited_search_for_vis(problem):\n",
        "    \"\"\"Search the deepest nodes in the search tree first.\"\"\"\n",
        "    iterations, all_node_colors, node = depth_limited_search_graph(problem)\n",
        "    return(iterations, all_node_colors, node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DIXWwXyCBYS"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=depth_limited_search_for_vis,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26arCdN5CBYS"
      },
      "source": [
        "## 8. ITERATIVE DEEPENING SEARCH\n",
        "\n",
        "Let's change all the 'node_colors' to starting position and define a different problem statement.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpEn9QVpCBYS"
      },
      "outputs": [],
      "source": [
        "def iterative_deepening_search_for_vis(problem):\n",
        "    for depth in range(sys.maxsize):\n",
        "        iterations, all_node_colors, node=depth_limited_search_for_vis(problem)\n",
        "        if iterations:\n",
        "            return (iterations, all_node_colors, node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_B99ZuqCBYS"
      },
      "outputs": [],
      "source": [
        "all_node_colors = []\n",
        "romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "display_visual(romania_graph_data, user_input=False,\n",
        "               algorithm=iterative_deepening_search_for_vis,\n",
        "               problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfAWU6-CBYS"
      },
      "source": [
        "## 9. GREEDY BEST FIRST SEARCH\n",
        "Let's change all the node_colors to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh7Xv2g9CBYS"
      },
      "outputs": [],
      "source": [
        "def greedy_best_first_search(problem, h=None):\n",
        "    \"\"\"Greedy Best-first graph search is an informative searching algorithm with f(n) = h(n).\n",
        "    You need to specify the h function when you call best_first_search, or\n",
        "    else in your Problem subclass.\"\"\"\n",
        "    h = memoize(h or problem.h, 'h')\n",
        "    iterations, all_node_colors, node = best_first_graph_search_for_vis(problem, lambda n: h(n))\n",
        "    return(iterations, all_node_colors, node)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYwj2cKhCBYS"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "# display_visual(romania_graph_data, user_input=False,\n",
        "#                algorithm=greedy_best_first_search,\n",
        "#                problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1TGibqCBYS"
      },
      "source": [
        "## 10. A\\* SEARCH\n",
        "\n",
        "Let's change all the `node_colors` to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toNeVtXXCBYS"
      },
      "outputs": [],
      "source": [
        "def astar_search_graph(problem, h=None):\n",
        "    \"\"\"A* search is best-first graph search with f(n) = g(n)+h(n).\n",
        "    You need to specify the h function when you call astar_search, or\n",
        "    else in your Problem subclass.\"\"\"\n",
        "    h = memoize(h or problem.h, 'h')\n",
        "    iterations, all_node_colors, node = best_first_graph_search_for_vis(problem,\n",
        "                                                                lambda n: n.path_cost + h(n))\n",
        "    return(iterations, all_node_colors, node)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD5ZbqRYCBYT"
      },
      "outputs": [],
      "source": [
        "all_node_colors = []\n",
        "romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "display_visual(romania_graph_data, user_input=False,\n",
        "               algorithm=astar_search_graph,\n",
        "               problem=romania_problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1QeUlDUCBYT"
      },
      "source": [
        "## 11. RECURSIVE BEST FIRST SEARCH\n",
        "Let's change all the `node_colors` to starting position and define a different problem statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew75rgWtCBYT"
      },
      "outputs": [],
      "source": [
        "def recursive_best_first_search_for_vis(problem, h=None):\n",
        "    \"\"\"[Figure 3.26] Recursive best-first search\"\"\"\n",
        "    # we use these two variables at the time of visualizations\n",
        "    iterations = 0\n",
        "    all_node_colors = []\n",
        "    node_colors = {k : 'white' for k in problem.graph.nodes()}\n",
        "\n",
        "    h = memoize(h or problem.h, 'h')\n",
        "\n",
        "    def RBFS(problem, node, flimit):\n",
        "        nonlocal iterations\n",
        "        def color_city_and_update_map(node, color):\n",
        "            node_colors[node.state] = color\n",
        "            nonlocal iterations\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            color_city_and_update_map(node, 'green')\n",
        "            return (iterations, all_node_colors, node), 0  # the second value is immaterial\n",
        "\n",
        "        successors = node.expand(problem)\n",
        "        if len(successors) == 0:\n",
        "            color_city_and_update_map(node, 'gray')\n",
        "            return (iterations, all_node_colors, None), infinity\n",
        "\n",
        "        for s in successors:\n",
        "            color_city_and_update_map(s, 'orange')\n",
        "            s.f = max(s.path_cost + h(s), node.f)\n",
        "\n",
        "        while True:\n",
        "            # Order by lowest f value\n",
        "            successors.sort(key=lambda x: x.f)\n",
        "            best = successors[0]\n",
        "            if best.f > flimit:\n",
        "                color_city_and_update_map(node, 'gray')\n",
        "                return (iterations, all_node_colors, None), best.f\n",
        "\n",
        "            if len(successors) > 1:\n",
        "                alternative = successors[1].f\n",
        "            else:\n",
        "                alternative = infinity\n",
        "\n",
        "            node_colors[node.state] = 'gray'\n",
        "            node_colors[best.state] = 'red'\n",
        "            iterations += 1\n",
        "            all_node_colors.append(dict(node_colors))\n",
        "            result, best.f = RBFS(problem, best, min(flimit, alternative))\n",
        "            if result[2] is not None:\n",
        "                color_city_and_update_map(node, 'green')\n",
        "                return result, best.f\n",
        "            else:\n",
        "                color_city_and_update_map(node, 'red')\n",
        "\n",
        "    node = Node(problem.initial)\n",
        "    node.f = h(node)\n",
        "\n",
        "    node_colors[node.state] = 'red'\n",
        "    iterations += 1\n",
        "    all_node_colors.append(dict(node_colors))\n",
        "    result, bestf = RBFS(problem, node, infinity)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V64mNZE4CBYT"
      },
      "outputs": [],
      "source": [
        "all_node_colors = []\n",
        "romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "display_visual(romania_graph_data, user_input=False,\n",
        "               algorithm=recursive_best_first_search_for_vis,\n",
        "               problem=romania_problem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "gcmAFGVvCBYT"
      },
      "outputs": [],
      "source": [
        "# all_node_colors = []\n",
        "# # display_visual(romania_graph_data, user_input=True, algorithm=breadth_first_tree_search)\n",
        "# algorithms = {  \"Breadth First Tree Search\": tree_breadth_search_for_vis,\n",
        "#                 \"Depth First Tree Search\": tree_depth_search_for_vis,\n",
        "#                 \"Breadth First Search\": breadth_first_search_graph,\n",
        "#                 \"Depth First Graph Search\": graph_search_for_vis,\n",
        "#                 \"Best First Graph Search\": best_first_graph_search_for_vis,\n",
        "#                 \"Uniform Cost Search\": uniform_cost_search_graph,\n",
        "#                 \"Depth Limited Search\": depth_limited_search_for_vis,\n",
        "#                 \"Iterative Deepening Search\": iterative_deepening_search_for_vis,\n",
        "#                 \"Greedy Best First Search\": greedy_best_first_search,\n",
        "#                 \"A-star Search\": astar_search_graph,\n",
        "#                 \"Recursive Best First Search\": recursive_best_first_search_for_vis}\n",
        "# display_visual(romania_graph_data, algorithm=algorithms, user_input=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfAXfkJYCBYT"
      },
      "source": [
        "## RECURSIVE BEST-FIRST SEARCH\n",
        "Recursive best-first search is a simple recursive algorithm that improves upon heuristic search by reducing the memory requirement.\n",
        "RBFS uses only linear space and it attempts to mimic the operation of standard best-first search.\n",
        "Its structure is similar to recursive depth-first search but it doesn't continue indefinitely down the current path, the `f_limit` variable is used to keep track of the f-value of the best _alternative_ path available from any ancestor of the current node.\n",
        "RBFS remembers the f-value of the best leaf in the forgotten subtree and can decide whether it is worth re-expanding the tree later.\n",
        "<br>\n",
        "However, RBFS still suffers from excessive node regeneration.\n",
        "<br>\n",
        "Let's have a look at the implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL7LCqVACBYT"
      },
      "outputs": [],
      "source": [
        "psource(recursive_best_first_search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX7rWC6OCBYU"
      },
      "source": [
        "This is how `recursive_best_first_search` can solve the `romania_problem`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQvImXKpCBYU"
      },
      "outputs": [],
      "source": [
        "# recursive_best_first_search(romania_problem).solution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nko8zdmzCBYU"
      },
      "source": [
        "`recursive_best_first_search` can be used to solve the 8 puzzle problem too, as discussed later."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}